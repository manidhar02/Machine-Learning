{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\"> Machine Learning- Assignment Task -2 </span>\n",
    "\n",
    "Manidhar Reddy - \n",
    "217503382\n",
    "\n",
    "### Part-1-Data Munging\n",
    "\n",
    "#### 1.1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as num\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = pd.read_csv(\"C:\\Users\\user\\Desktop\\ML python files\\Assessment-task-2\\data\\wisconsin_data/train_wbcd.csv\", delimiter=',')\n",
    "#print traindata\n",
    "\n",
    "testdata = pd.read_csv(\"C:\\Users\\user\\Desktop\\ML python files\\Assessment-task-2\\data\\wisconsin_data/test_wbcd.csv\", delimiter=',')\n",
    "#print testdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the number of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in train data are : 30\n",
      "Number of features in test data are  : 30\n"
     ]
    }
   ],
   "source": [
    "train_feature = traindata.iloc[:,2:32]\n",
    "print \"Number of features in train data are :\",len(train_feature.T)\n",
    "\n",
    "test_feature = testdata.iloc[:,2:32]\n",
    "print \"Number of features in test data are  :\",len(test_feature.T)\n",
    "train_labels =  traindata.iloc[:,1]\n",
    "test_labels =  testdata.iloc[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "printing the total number of 1's and 0's in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of 0's in train data is 42\n",
      "No of 1's in train data is 58\n",
      "No of 0's in test data is 4\n",
      "No of 1's in train data is 16\n"
     ]
    }
   ],
   "source": [
    "#Assuming B as 0's and M as 1's  \n",
    "def count(labels): \n",
    "    B_count = 0\n",
    "    M_count = 0\n",
    "    for count in range (len(labels)):\n",
    "        if train_labels[count] == 'M':\n",
    "            B_count+=1\n",
    "        else: \n",
    "            M_count+=1\n",
    "    return B_count,M_count\n",
    "\n",
    "B_count, M_count= count(train_labels)\n",
    "print \"No of 0's in train data is {}\".format(B_count)\n",
    "print \"No of 1's in train data is {}\".format(M_count)\n",
    "B_count, M_count= count (test_labels)\n",
    "print \"No of 0's in test data is {}\".format(B_count)\n",
    "print \"No of 1's in train data is {}\".format(M_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on class distibuton: In the rain data class distribution is slightly balanced.As we can see that occurences of both 0's and 1's are nearly 50%. Test data is unbalanced.Occurrences of 1's is high when compared to 0's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the number of features with missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing entries in training set:  1\n",
      "Features with missing entries in test set 1\n"
     ]
    }
   ],
   "source": [
    "train_wbcd = pd.read_csv('C:\\Users\\user\\Desktop\\ML python files\\Assessment-task-2\\data\\wisconsin_data/train_wbcd.csv', delimiter=',',header=0 ).values\n",
    "test_wbcd = pd.read_csv('C:\\Users\\user\\Desktop\\ML python files\\Assessment-task-2\\data\\wisconsin_data/test_wbcd.csv',delimiter=',',header=0 ).values\n",
    "x_trained=np.array(train_wbcd[0:100,2:32])\n",
    "x_tested=np.array(test_wbcd[0:20,2:32])\n",
    "null_train=num.count_nonzero(sum(pd.isnull(x_trained)))\n",
    "print \"Features with missing entries in training set: \",null_train\n",
    "null_test=num.count_nonzero(sum(pd.isnull(x_tested)))\n",
    "print \"Features with missing entries in test set\",null_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing entries with the mean of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing entries in training set :  0\n",
      "Median of train data feature F21 is: 15.315\n",
      "Median of train data feature F21 is: 15.315\n",
      "Features with missing entries in test set :  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_feature [\"f21\"] =train_feature [\"f21\"].fillna(train_feature [\"f21\"].median() )\n",
    "print \"Features with missing entries in training set : \",pd.isnull(train_feature).sum().sum()\n",
    "\n",
    "print \"Median of train data feature F21 is:\",train_feature [\"f21\"].median()\n",
    "test_feature [\"f21\"] =test_feature [\"f21\"].fillna(test_feature [\"f21\"].median() )\n",
    "\n",
    "print \"Median of train data feature F21 is:\",train_feature [\"f21\"].median()\n",
    "print \"Features with missing entries in test set : \",pd.isnull(test_feature).sum().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature = scale(train_feature)\n",
    "#print train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_feature = scale(test_feature)\n",
    "#print test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Logistic Regression\n",
    "\n",
    "We have normalized the train and test data.Now we will be performing the logistic regression to the normalized data.<br />\n",
    "L1 regularization and L2 regularization using <br/> alpha = 0.1 <br/> lambda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100L, 30L)\n",
      "(100L,)\n",
      "(20L, 30L)\n",
      "(20L,)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression of L1 penalty\n",
    "# initialize the logisitc regression model. \n",
    "my_model1 = LogisticRegression(C=10,penalty='l1')\n",
    "\n",
    "#Create the training/testing data and labels\n",
    "Xtrain = num.array(train_feature[:,:])\n",
    "ytrain = traindata.iloc[:,1]\n",
    "\n",
    "#lb = preprocessing.LabelBinarizer()\n",
    "#lb.fit(ytrain.values)\n",
    "\n",
    "Xtest = num.array(test_feature[:,:])\n",
    "ytest =  testdata.iloc[:,1]\n",
    "\n",
    "print Xtrain.shape\n",
    "print ytrain.shape\n",
    "print Xtest.shape\n",
    "print ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model1.fit(Xtrain, ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labels are       : ['B' 'M' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M']\n",
      "\n",
      "Model predicted labels are: ['B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M'\n",
      " 'B' 'M']\n"
     ]
    }
   ],
   "source": [
    "predict_label1 = my_model1.predict(Xtest)\n",
    "\n",
    "#the original label is ytest\n",
    "true_label1 = ytest.values\n",
    "\n",
    "print \"The true labels are       : {}\".format(true_label1)\n",
    "print\n",
    "print \"Model predicted labels are: {}\".format(predict_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is : 0.9\n",
      "Model accuracy is : 90.0%\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[13  1]\n",
      " [ 1  5]]\n",
      "\n",
      "Precision score is : 0.9\n",
      "Recall score is:  0.9\n",
      "F1-Score is : 0.9\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy score is :\",accuracy_score(true_label1, predict_label1)\n",
    "print \"Model accuracy is : {}%\".format(num.round(accuracy_score(true_label1, predict_label1)*100, decimals=2))\n",
    "\n",
    "print\n",
    "\n",
    "print \"Confusion Matrix is :\"\n",
    "print confusion_matrix(true_label1, predict_label1, labels=[\"B\", \"M\"])\n",
    "print\n",
    "print \"Precision score is :\",precision_score(true_label1, predict_label1,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "print \"Recall score is: \",recall_score(true_label1, predict_label1,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "print \"F1-Score is :\",f1_score(true_label1, predict_label1,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression of L2 penalty\n",
    "my_model2 = LogisticRegression(C=10,penalty='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model2.fit(Xtrain, ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labels are       : ['B' 'M' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M']\n",
      "\n",
      "Model predicted labels are: ['B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M'\n",
      " 'B' 'M']\n"
     ]
    }
   ],
   "source": [
    "predict_label2 = my_model2.predict(Xtest)\n",
    "\n",
    "#the original label is ytest\n",
    "true_label2 = ytest.values\n",
    "\n",
    "print \"The true labels are       : {}\".format(true_label2)\n",
    "print\n",
    "print \"Model predicted labels are: {}\".format(predict_label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "Model accuracy is: 90.0%\n",
      "Confusion Matrix is :\n",
      "[[13  1]\n",
      " [ 1  5]]\n",
      "\n",
      "Precision score is : 0.9\n",
      "Recall score is:  0.9\n",
      "F1-Score is : 0.9\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(true_label2, predict_label2)\n",
    "print \"Model accuracy is: {}%\".format(num.round(accuracy_score(true_label2, predict_label2)*100, decimals=2))\n",
    "\n",
    "\n",
    "print \"Confusion Matrix is :\"\n",
    "print confusion_matrix(true_label2, predict_label2, labels=[\"B\", \"M\"])\n",
    "print\n",
    "print \"Precision score is :\",precision_score(true_label2, predict_label2,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "print \"Recall score is: \",recall_score(true_label2, predict_label2,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "print \"F1-Score is :\",f1_score(true_label2, predict_label2,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Choosing the correct hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def besthyperparameter(val,regularization):\n",
    "    trials=100\n",
    "    c_val = 1/val\n",
    "    my_model = LogisticRegression(C=c_val,penalty=regularization)\n",
    "    model_accs  = num.zeros(trials)  # storing model accuracy\n",
    "    #model_wts   = num.zeros([trials, 31]) # storing model weights\n",
    "    \n",
    "    #print train_feature\n",
    "    #print traindata.iloc[:,1]\n",
    "    #print num.array(train_feature.join(traindata[:,1]))\n",
    "    #print train_feature\n",
    "    \n",
    "    for i in range(0,trials):\n",
    "    \n",
    "             \n",
    "        Dtrain, Dval = train_test_split((num.column_stack((train_feature,(traindata.iloc[:,1])))), test_size=0.3)\n",
    "    \n",
    "        #print Dtrain\n",
    "        #print Dval\n",
    "        Xtrain = num.array(Dtrain[:, 0:30])\n",
    "        ytrain = num.array(Dtrain[:,30])\n",
    "\n",
    "        #print Xtrain\n",
    "        #print ytrain\n",
    "        Xval = num.array(Dval[:, 0:30])\n",
    "        yval = num.array(Dval[:,30])\n",
    "                \n",
    "        my_model.fit(Xtrain,ytrain)\n",
    "        \n",
    "        ypredicts = my_model.predict(Xval)\n",
    "        ytruelabels = yval\n",
    "        model_accs[i]  = accuracy_score(yval, ypredicts)\n",
    "        \n",
    "    return num.mean(model_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score when alpha is 0.1 using L1 model is : 0.981333333333\n",
      "Accuracy Score when alpha is 1 using L1 model is : 0.985\n",
      "Accuracy Score when alpha is 3 using L1 model is : 0.972333333333\n",
      "Accuracy Score when alpha is 10 using L1 model is : 0.937333333333\n",
      "Accuracy Score when alpha is 33 using L1 model is : 0.588666666667\n",
      "Accuracy Score when alpha is 100 using L1 model is : 0.581666666667\n",
      "Accuracy Score when alpha is 333 using L1 model is : 0.580666666667\n",
      "Accuracy Score when alpha is 1000 using L1 model is : 0.589333333333\n",
      "Accuracy Score when alpha is 3333 using L1 model is : 0.584333333333\n",
      "Accuracy Score when alpha is 10000 using L1 model is : 0.593333333333\n",
      "Accuracy Score when alpha is 33333 using L1 model is : 0.571\n",
      "Best Alpha: 1\n"
     ]
    }
   ],
   "source": [
    "alpha_vals = [0.1,1,3,10,33,100,333,1000, 3333, 10000, 33333]\n",
    "l1_acc = num.zeros(len(alpha_vals))\n",
    "index=0\n",
    "\n",
    "for l in alpha_vals:\n",
    "    l1_acc[index] = besthyperparameter(num.float(l),'l1')\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "for acc_val in alpha_vals:\n",
    "    print \"Accuracy Score when alpha is {} using L1 model is : {}\".format(alpha_vals[index],l1_acc[index])\n",
    "    index+=1\n",
    "    \n",
    "max_index_l1  = num.argmax(l1_acc)\n",
    "best_alpha = alpha_vals[max_index_l1]\n",
    "    \n",
    "print \"Best Alpha: {}\".format(best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Under fitting/Over-fitting for L1 regression\n",
    "\n",
    "We calculated the accuracy of the model using with the alpha values 0.1,1,3,10,33,100,333,1000, 3333,10000, 33333.We can observe that there is a raise in the accuracy score. But at caertain point where alpha= 3 the accuracy score will drops from 98.5% to 97% indicating that this model is responding highly for smaller change which shows that the model is overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score when lambda is 0.001 using L2 model is : 0.989333333333\n",
      "Accuracy Score when lambda is 0.003 using L2 model is : 0.989666666667\n",
      "Accuracy Score when lambda is 0.01 using L2 model is : 0.992\n",
      "Accuracy Score when lambda is 0.03 using L2 model is : 0.991666666667\n",
      "Accuracy Score when lambda is 0.1 using L2 model is : 0.991333333333\n",
      "Accuracy Score when lambda is 0.3 using L2 model is : 0.992666666667\n",
      "Accuracy Score when lambda is 1 using L2 model is : 0.991333333333\n",
      "Accuracy Score when lambda is 3 using L2 model is : 0.99\n",
      "Accuracy Score when lambda is 10 using L2 model is : 0.986333333333\n",
      "Accuracy Score when lambda is 33 using L2 model is : 0.979\n",
      "Best Lambda: 0.3\n"
     ]
    }
   ],
   "source": [
    "lambda_vals = [0.001, 0.003, 0.01, 0.03, 0.1,0.3,1,3,10,33]\n",
    "l2_acc = num.zeros(len(lambda_vals))\n",
    "index=0\n",
    "\n",
    "for l in lambda_vals:\n",
    "    l2_acc[index] = besthyperparameter(num.float(l),'l2')\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "for acc_val in lambda_vals:\n",
    "    print \"Accuracy Score when lambda is {} using L2 model is : {}\".format(lambda_vals[index],l2_acc[index])\n",
    "    index+=1\n",
    "    \n",
    "max_index_l2  = num.argmax(l2_acc)\n",
    "best_lambda = lambda_vals[max_index_l2]\n",
    "    \n",
    "print \"Best Lambda: {}\".format(best_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Under fitting/Over-fitting for L2 regression\n",
    "\n",
    "We calculated the accuracy of the model using with the alpha values 0.001, 0.003, 0.01, 0.03,0.1,0.3,1,3,10,33.We can observe that there is a constant in the accuracy score. But at caertain point where alpha=0.3  the accuracy score will increased slightly. The complexity of the model is increasing but accuracy is increasing very slightly which indicating that this model is  overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrainModel(val,regularization):\n",
    "    \n",
    "    c_val=num.float(1/val)\n",
    "    my_model = LogisticRegression(C=c_val,penalty=regularization)\n",
    "\n",
    "    #Create the training/testing data and labels\n",
    "    Xtrain = num.array(train_feature[:,:])\n",
    "    ytrain = traindata.iloc[:,1]\n",
    "\n",
    "    Xtest = num.array(test_feature[:,:])\n",
    "    ytest = testdata.iloc[:,1]\n",
    "    \n",
    "    my_model.fit(Xtrain, ytrain.values)\n",
    "    \n",
    "    predict_label = my_model.predict(Xtest)\n",
    "\n",
    "    #the original label is ytest\n",
    "    true_label = ytest.values\n",
    "\n",
    "    model_weights   = my_model.coef_\n",
    "    weights = ((num.argsort(model_weights))[0])[::-1]\n",
    "    \n",
    "    print accuracy_score(true_label, predict_label)\n",
    "    print \"Model accuracy is: {}%\".format(num.round(accuracy_score(true_label, predict_label)*100, decimals=2))\n",
    "\n",
    "    print \"Confusion Matrix is :\"\n",
    "    print confusion_matrix(true_label, predict_label, labels=[\"B\", \"M\"])\n",
    "    print\n",
    "    print \"Precision score is :\",precision_score(true_label, predict_label,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "    print \"Recall score is: \",recall_score(true_label, predict_label,labels=[\"B\",\"M\"],average='weighted')\n",
    "\n",
    "    print \"F1-Score is :\",f1_score(true_label, predict_label,average='weighted')\n",
    "    print\n",
    "    print \"Top 5 features selected in decreasing order of feature weights are:\"\n",
    "    print weights[0:5]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "Model accuracy is: 95.0%\n",
      "Confusion Matrix is :\n",
      "[[14  0]\n",
      " [ 1  5]]\n",
      "\n",
      "Precision score is : 0.953333333333\n",
      "Recall score is:  0.95\n",
      "F1-Score is : 0.948589341693\n",
      "\n",
      "Top 5 features selected in decreasing order of feature weights are:\n",
      "[23 21 22 25  8]\n"
     ]
    }
   ],
   "source": [
    "retrainModel(best_alpha,'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "Model accuracy is: 90.0%\n",
      "Confusion Matrix is :\n",
      "[[13  1]\n",
      " [ 1  5]]\n",
      "\n",
      "Precision score is : 0.9\n",
      "Recall score is:  0.9\n",
      "F1-Score is : 0.9\n",
      "\n",
      "Top 5 features selected in decreasing order of feature weights are:\n",
      "[22  2 25 21 23]\n"
     ]
    }
   ],
   "source": [
    "retrainModel(best_lambda,'l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2-Multi-class classification\n",
    "2.1 creating a default One-vs-Rest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points are : 2520\n",
      "Total Number of features in data are : 784\n",
      "Unique labels in the data are : [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\Users\\user\\Desktop\\ML python files\\Assessment-task-2\\data/mnist/reduced_mnist.csv\", delimiter=',')\n",
    "print \"Number of data points are :\", len(data)\n",
    "\n",
    "data_feature = data.iloc[:,1:]\n",
    "print \"Total Number of features in data are :\",len(data_feature.T)\n",
    "\n",
    "unique_labels = num.unique(data.iloc[:,0])\n",
    "print \"Unique labels in the data are :\", unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766\n",
      "754\n"
     ]
    }
   ],
   "source": [
    "msk = num.random.rand(len(data)) < 0.7\n",
    "\n",
    "train = data[msk]\n",
    "\n",
    "test = data[~msk]\n",
    "\n",
    "print len(train)\n",
    "print len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onevsrestClassifier(val):\n",
    "    c_val=num.float(1/val)\n",
    "    my_model = LogisticRegression(C=c_val,penalty='l1')\n",
    "\n",
    "    #Create the training/testing data and labels\n",
    "    Xtrain = train.iloc[:,:]\n",
    "    ytrain = train.iloc[:,0]\n",
    "\n",
    "    #lb = preprocessing.LabelBinarizer()\n",
    "    #lb.fit(ytrain.values)\n",
    "\n",
    "    Xtest = test.iloc[:,:]\n",
    "    ytest = test.iloc[:,0]\n",
    "    \n",
    "    my_model.fit(Xtrain.values, ytrain.values)\n",
    "    \n",
    "    predict_label = my_model.predict(Xtest)\n",
    "\n",
    "    #the original label is ytest\n",
    "    true_label = ytest.values\n",
    "    \n",
    "    print accuracy_score(true_label, predict_label)\n",
    "    print \"Model accuracy is: {}%\".format(num.round(accuracy_score(true_label, predict_label)*100, decimals=2))\n",
    "\n",
    "    print \"Confusion Matrix is :\"\n",
    "    print confusion_matrix(true_label, predict_label)\n",
    "    print\n",
    "    print \"Precision score is :\",precision_score(true_label, predict_label,average='weighted')\n",
    "\n",
    "    print \"Recall score is: \",recall_score(true_label, predict_label,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839522546419\n",
      "Model accuracy is: 83.95%\n",
      "Confusion Matrix is :\n",
      "[[62  0  1  3  0  1  1  0  4  0]\n",
      " [ 0 87  0  0  0  2  0  0  0  0]\n",
      " [ 0  1 54  2  2  1  5  1  6  0]\n",
      " [ 0  2  2 70  0  6  0  0  1  0]\n",
      " [ 1  0  1  1 58  1  1  0  1  3]\n",
      " [ 3  0  0  6  1 54  3  0  4  1]\n",
      " [ 1  0  1  0  0  0 63  0  5  0]\n",
      " [ 0  1  5  2  2  0  0 70  6  1]\n",
      " [ 1  7  3  2  0  3  0  0 55  1]\n",
      " [ 1  0  0  1  5  1  1  2  1 60]]\n",
      "\n",
      "Precision score is : 0.844280698491\n",
      "Recall score is:  0.839522546419\n"
     ]
    }
   ],
   "source": [
    "onevsrestClassifier(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Choosing the best hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choosebestvalhyperparameter(val):\n",
    "    trials=10\n",
    "    c_val = 1/val\n",
    "    my_model = LogisticRegression(C=c_val,penalty='l1')\n",
    "    model_accs  = num.zeros(trials)  # storing model accuracy\n",
    "      \n",
    "    for i in range(0,trials):\n",
    "        Dtrain, Dval = train_test_split(train.iloc[:,:], test_size=0.3)\n",
    "    \n",
    "        #print Dtrain\n",
    "        #print Dval\n",
    "        Xtrain = Dtrain.iloc[:, 1:]\n",
    "        ytrain = Dtrain.iloc[:,0]\n",
    "\n",
    "        #print Xtrain\n",
    "        #print ytrain\n",
    "        Xval = Dval.iloc[:, 1:]\n",
    "        yval = Dval.iloc[:,0]\n",
    "        \n",
    "        my_model.fit(Xtrain,ytrain)\n",
    "        \n",
    "        ypredicts = my_model.predict(Xval)\n",
    "        ytruelabels = yval\n",
    "        model_accs[i]  = accuracy_score(ytruelabels, ypredicts)\n",
    "        \n",
    "    return num.mean(model_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score when alpha is 0.1 using L1 model is : 0.843396226415\n",
      "Accuracy Score when alpha is 1 using L1 model is : 0.840377358491\n",
      "Accuracy Score when alpha is 3 using L1 model is : 0.842075471698\n",
      "Accuracy Score when alpha is 10 using L1 model is : 0.830754716981\n",
      "Accuracy Score when alpha is 33 using L1 model is : 0.837547169811\n",
      "Accuracy Score when alpha is 100 using L1 model is : 0.856037735849\n",
      "Accuracy Score when alpha is 333 using L1 model is : 0.866603773585\n",
      "Accuracy Score when alpha is 1000 using L1 model is : 0.852641509434\n",
      "Accuracy Score when alpha is 3333 using L1 model is : 0.806226415094\n",
      "Accuracy Score when alpha is 10000 using L1 model is : 0.70679245283\n",
      "Accuracy Score when alpha is 33333 using L1 model is : 0.542264150943\n",
      "Best Alpha: 333\n"
     ]
    }
   ],
   "source": [
    "alpha_vals = [0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333]\n",
    "\n",
    "l1_val_acc = num.zeros(len(alpha_vals))\n",
    "index=0\n",
    "\n",
    "for l in alpha_vals:\n",
    "    l1_val_acc[index] = choosebestvalhyperparameter(num.float(l))\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "for acc_val in alpha_vals:\n",
    "    print \"Accuracy Score when alpha is {} using L1 model is : {}\".format(alpha_vals[index],l1_val_acc[index])\n",
    "    index+=1\n",
    "    \n",
    "max_index_l1_val  = num.argmax(l1_val_acc)\n",
    "best_val_alpha = alpha_vals[max_index_l1_val]\n",
    "    \n",
    "print \"Best Alpha: {}\".format(best_val_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choosebesttrainhyperparameter(val):\n",
    "    trials=10\n",
    "    c_val = 1/val\n",
    "    my_model = LogisticRegression(C=c_val,penalty='l1')\n",
    "    model_accs  = num.zeros(trials)  # storing model accuracy\n",
    "        \n",
    "    for i in range(0,trials):\n",
    "        Dtrain, Dval = train_test_split(data.iloc[:,:], test_size=0.3)\n",
    "    \n",
    "        Xtrain = Dtrain.iloc[:, 1:]\n",
    "        ytrain = Dtrain.iloc[:,0]\n",
    "\n",
    "        Xtest = Dval.iloc[:, 1:]\n",
    "        ytest = Dval.iloc[:,0]\n",
    "                \n",
    "        my_model.fit(Xtrain,ytrain)\n",
    "        \n",
    "        ypredicts = my_model.predict(Xtest)\n",
    "        ytruelabels = ytest\n",
    "        model_accs[i]  = accuracy_score(ytruelabels, ypredicts)\n",
    "        \n",
    "    return num.mean(model_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score when alpha is 0.1 using L1 model is : 0.831613756614\n",
      "Accuracy Score when alpha is 1 using L1 model is : 0.832407407407\n",
      "Accuracy Score when alpha is 3 using L1 model is : 0.839285714286\n",
      "Accuracy Score when alpha is 10 using L1 model is : 0.838888888889\n",
      "Accuracy Score when alpha is 33 using L1 model is : 0.843518518519\n",
      "Accuracy Score when alpha is 100 using L1 model is : 0.856878306878\n",
      "Accuracy Score when alpha is 333 using L1 model is : 0.869708994709\n",
      "Accuracy Score when alpha is 1000 using L1 model is : 0.86044973545\n",
      "Accuracy Score when alpha is 3333 using L1 model is : 0.833862433862\n",
      "Accuracy Score when alpha is 10000 using L1 model is : 0.73544973545\n",
      "Accuracy Score when alpha is 33333 using L1 model is : 0.604100529101\n",
      "Best Alpha: 333\n"
     ]
    }
   ],
   "source": [
    "alpha_vals = [0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333]\n",
    "\n",
    "l1_train_acc = num.zeros(len(alpha_vals))\n",
    "index=0\n",
    "\n",
    "for l in alpha_vals:\n",
    "    l1_train_acc[index] = choosebesttrainhyperparameter(num.float(l))\n",
    "    index+=1\n",
    "\n",
    "index = 0\n",
    "for acc_val in alpha_vals:\n",
    "    print \"Accuracy Score when alpha is {} using L1 model is : {}\".format(alpha_vals[index],l1_train_acc[index])\n",
    "    index+=1\n",
    "    \n",
    "max_index_l1_train  = num.argmax(l1_train_acc)\n",
    "best_train_alpha = alpha_vals[max_index_l1_train]\n",
    "    \n",
    "print \"Best Alpha: {}\".format(best_train_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10886e10>"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAESCAYAAAAG+ZUXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf21a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the accuracy curve\n",
    "plt.plot(range(0,len(alpha_vals)), l1_val_acc, color='b', label='Validation Acuracy')\n",
    "plt.plot(range(0,len(alpha_vals)), l1_train_acc, color='r', label='Training Accuracy')\n",
    "#replace the x-axis labels with penalty values\n",
    "plt.xticks(range(0,len(alpha_vals)), alpha_vals, rotation='vertical') \n",
    "\n",
    "#Highlight the best values of alpha and lambda\n",
    "plt.plot((max_index_l1_val, max_index_l1_val), (0, l1_val_acc[max_index_l1_val]), ls='dotted', color='b')\n",
    "plt.plot((max_index_l1_train, max_index_l1_train), (0, l1_train_acc[max_index_l1_train]), ls='dotted', color='r')\n",
    "\n",
    "#Set the y-axis from 0 to 1.0\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0, 1.0])\n",
    "\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph represents the graph for validation accuracy and training accuracy. Accuracy score is constant for the alpha values till alpha=333.From there the accuracy score is decreasing for the increase in alpha values which indicates the region of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got the best alpha values from the above computation and now we will evaluate the performance on the test data and find \n",
    "1. Number of non-zero features\n",
    "2. Confusion matrix\n",
    "3. Precision\n",
    "4. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrainfinalModel(val):\n",
    "    \n",
    "    c_val=num.float(1/val)\n",
    "    my_model = LogisticRegression(C=c_val,penalty='l1')\n",
    "\n",
    "    #Create the training/testing data and labels\n",
    "    Xtrain = train.iloc[:,:]\n",
    "    ytrain = train.iloc[:,0]\n",
    "\n",
    "    #lb = preprocessing.LabelBinarizer()\n",
    "    #lb.fit(ytrain.values)\n",
    "\n",
    "    Xtest = test.iloc[:,:]\n",
    "    ytest = test.iloc[:,0]\n",
    "    \n",
    "    my_model.fit(Xtrain.values, ytrain.values)\n",
    "    \n",
    "    predict_label = my_model.predict(Xtest)\n",
    "\n",
    "    #the original label is ytest\n",
    "    true_label = ytest.values\n",
    "\n",
    "    print \"Number of non-zero feautres are: \", num.count_nonzero(my_model.coef_)\n",
    "    print\n",
    "\n",
    "    print \"Confusion Matrix is :\"\n",
    "    print confusion_matrix(true_label, predict_label)\n",
    "    \n",
    "    cm = confusion_matrix(true_label, predict_label)\n",
    "    TP = num.diag(cm)\n",
    "    FP = cm.sum(axis=0) - num.diag(cm)\n",
    "    FN = cm.sum(axis=1) - num.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    accuracy = []\n",
    "    \n",
    "    while i in range(0,10):\n",
    "        precision.append(float(TP[i])/float(TP[i] + FP[i]))\n",
    "        recall.append(float(TP[i])/float(TP[i]+FN[i]))\n",
    "        accuracy.append(float(TP[i] + TN[i])/float(TP[i]+TN[i]+FP[i]+FN[i])*100)\n",
    "        i+=1\n",
    "    \n",
    "    i=0\n",
    "    print\n",
    "    print \"Labels                    Precision                        Recall                               Accuracy\"\n",
    "    while i in range(0,10):\n",
    "           print \"{}                        {}                   {}                        {}\" .format(i,precision[i],recall[i],accuracy[i])\n",
    "           print\n",
    "           i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero feautres are:  2588\n",
      "\n",
      "Confusion Matrix is :\n",
      "[[63  0  1  3  0  0  1  0  4  0]\n",
      " [ 0 87  0  0  0  2  0  0  0  0]\n",
      " [ 0  1 53  2  2  1  6  1  6  0]\n",
      " [ 0  1  2 71  0  6  0  0  1  0]\n",
      " [ 1  0  1  1 58  1  1  0  1  3]\n",
      " [ 3  0  0  6  1 54  3  0  4  1]\n",
      " [ 1  0  1  0  0  0 63  0  5  0]\n",
      " [ 0  1  5  2  2  0  0 71  5  1]\n",
      " [ 1  5  3  2  0  4  0  0 55  2]\n",
      " [ 1  0  0  1  5  1  1  1  2 60]]\n",
      "\n",
      "Labels                    Precision                        Recall                               Accuracy\n",
      "0                        0.9                   0.875                        97.8779840849\n",
      "\n",
      "1                        0.915789473684                   0.977528089888                        98.6737400531\n",
      "\n",
      "2                        0.80303030303                   0.736111111111                        95.7559681698\n",
      "\n",
      "3                        0.806818181818                   0.876543209877                        96.4190981432\n",
      "\n",
      "4                        0.852941176471                   0.865671641791                        97.4801061008\n",
      "\n",
      "5                        0.782608695652                   0.75                        95.6233421751\n",
      "\n",
      "6                        0.84                   0.9                        97.4801061008\n",
      "\n",
      "7                        0.972602739726                   0.816091954023                        97.6127320955\n",
      "\n",
      "8                        0.66265060241                   0.763888888889                        94.0318302387\n",
      "\n",
      "9                        0.89552238806                   0.833333333333                        97.4801061008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrainfinalModel(num.float(best_alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Over-fitting/ Under fitting\n",
    "We can observe that for alpha values  0.1,1,3,10,33,100,333,1000,3333,10000,33333 we can observe that there is a raise in the accuracy score of training data and validation data. But there is a sudden drop in accuracy from 86% to 82% when alpha = 3333. It is indicating that model is reponding highly for smaller change in the alpha value. So this model is overfitting.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
